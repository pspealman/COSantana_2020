---
title: "Project_Boris"
author: "Carolina Oliveira de Santana"
date: "2/29/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this section we train QIIME2 feature-classifier using the SILVA_132 data set

```{bash}
qiime tools import \
  --type 'FeatureData[Sequence]' \
  --input-path  SILVA_132_QIIME_release/rep_set/rep_set_16S_only/97/silva_132_97_16S.fna \
  --output-path silva_132_97_16S.qza
  
qiime tools import \
  --type 'FeatureData[Taxonomy]' \
  --input-format HeaderlessTSVTaxonomyFormat \
  --input-path SILVA_132_QIIME_release/taxonomy/16S_only/97/taxonomy_all_levels.txt \
  --output-path ref-taxonomy.qza
  
qiime feature-classifier extract-reads \
  --i-sequences silva_132_97_16S.qza \
  --p-f-primer GTGCCAGCMGCCGCGGTAA \
  --p-r-primer GGACTACHVGGGTWTCTAAT \
  --p-trunc-len 120 \
  --p-min-length 100 \
  --p-max-length 400 \
  --o-reads ref-seqs.qza
  
qiime feature-classifier classify-sklearn \
  --i-classifier classifier.qza \
  --i-reads rep-seqs.qza \
  --o-classification taxonomy.qza

qiime metadata tabulate \
  --m-input-file taxonomy.qza \
  --o-visualization taxonomy.qzv

```

In this section we combine left and right reads using the 'join_paired_ends.py' script from Qiime.  

```{bash}
#variable_names
directory=P1_1-227388221/
fastq_file_1=P1-1_S36_L001_R1_001
fastq_file_2=P1-1_S36_L001_R2_001
output_name=P1-1
#commands
	java -jar /scratch/cod264/cod264/Trimmomatic-0.39/trimmomatic-0.39.jar PE -phred33 ${directory}${fastq_file_1}.fastq.gz  ${directory}${fastq_file_2}.fastq.gz ${directory}${output_name}_forward_paired.fq.gz ${directory}${output_name}_forward_unpaired.fq.gz ${directory}${output_name}_reverse_paired.fq.gz ${directory}${output_name}_reverse_unpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:100
	join_paired_ends.py -f ${directory}${output_name}_forward_paired.fq.gz -r ${directory}${output_name}_reverse_paired.fq.gz -o ${directory}${output_name}_paired.fq -j 4 -p 1
	# #to check the number of surviving seqeunces use 
	wc -l ${directory}${output_name}_paired.fq/fastqjoin.join.fastq
	# # this will print out the number
	convert_fastaqual_fastq.py -f ${directory}${output_name}_paired.fq/fastqjoin.join.fastq -c fastq_to_fastaqual -o ${directory}

#variable_names
directory=P1_2-227388216/
fastq_file_1=P1-2_S37_L001_R1_001
fastq_file_2=P1-2_S37_L001_R2_001
output_name=P1-2
#commands
	java -jar /scratch/cod264/cod264/Trimmomatic-0.39/trimmomatic-0.39.jar PE -phred33 ${directory}${fastq_file_1}.fastq.gz  ${directory}${fastq_file_2}.fastq.gz ${directory}${output_name}_forward_paired.fq.gz ${directory}${output_name}_forward_unpaired.fq.gz ${directory}${output_name}_reverse_paired.fq.gz ${directory}${output_name}_reverse_unpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:100
	join_paired_ends.py -f ${directory}${output_name}_forward_paired.fq.gz -r ${directory}${output_name}_reverse_paired.fq.gz -o ${directory}${output_name}_paired.fq -j 4 -p 1
	# #to check the number of surviving seqeunces use 
	wc -l ${directory}${output_name}_paired.fq/fastqjoin.join.fastq
	# # this will print out the number
	convert_fastaqual_fastq.py -f ${directory}${output_name}_paired.fq/fastqjoin.join.fastq -c fastq_to_fastaqual -o ${directory}


#variable_names
directory=P1_3-227388220/
fastq_file_1=P1-3_S38_L001_R1_001
fastq_file_2=P1-3_S38_L001_R2_001
output_name=P1-3
#commands
	java -jar /scratch/cod264/cod264/Trimmomatic-0.39/trimmomatic-0.39.jar PE -phred33 ${directory}${fastq_file_1}.fastq.gz  ${directory}${fastq_file_2}.fastq.gz ${directory}${output_name}_forward_paired.fq.gz ${directory}${output_name}_forward_unpaired.fq.gz ${directory}${output_name}_reverse_paired.fq.gz ${directory}${output_name}_reverse_unpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:100
	join_paired_ends.py -f ${directory}${output_name}_forward_paired.fq.gz -r ${directory}${output_name}_reverse_paired.fq.gz -o ${directory}${output_name}_paired.fq -j 4 -p 1
	# #to check the number of surviving seqeunces use 
	wc -l ${directory}${output_name}_paired.fq/fastqjoin.join.fastq
	# # this will print out the number
	convert_fastaqual_fastq.py -f ${directory}${output_name}_paired.fq/fastqjoin.join.fastq -c fastq_to_fastaqual -o ${directory}
	
	
#variable_names
directory=P2_1-227388222/
fastq_file_1=P2-1_S39_L001_R1_001
fastq_file_2=P2-1_S39_L001_R2_001
output_name=P2-1
#commands
	java -jar /scratch/cod264/cod264/Trimmomatic-0.39/trimmomatic-0.39.jar PE -phred33 ${directory}${fastq_file_1}.fastq.gz  ${directory}${fastq_file_2}.fastq.gz ${directory}${output_name}_forward_paired.fq.gz ${directory}${output_name}_forward_unpaired.fq.gz ${directory}${output_name}_reverse_paired.fq.gz ${directory}${output_name}_reverse_unpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:100
	join_paired_ends.py -f ${directory}${output_name}_forward_paired.fq.gz -r ${directory}${output_name}_reverse_paired.fq.gz -o ${directory}${output_name}_paired.fq -j 4 -p 1
	# #to check the number of surviving seqeunces use 
	wc -l ${directory}${output_name}_paired.fq/fastqjoin.join.fastq
	# # this will print out the number
	convert_fastaqual_fastq.py -f ${directory}${output_name}_paired.fq/fastqjoin.join.fastq -c fastq_to_fastaqual -o ${directory}


#variable_names
directory=P2_2-227388214/
fastq_file_1=P2-2_S40_L001_R1_001
fastq_file_2=P2-2_S40_L001_R2_001
output_name=P2-2
#commands
	java -jar /scratch/cod264/cod264/Trimmomatic-0.39/trimmomatic-0.39.jar PE -phred33 ${directory}${fastq_file_1}.fastq.gz  ${directory}${fastq_file_2}.fastq.gz ${directory}${output_name}_forward_paired.fq.gz ${directory}${output_name}_forward_unpaired.fq.gz ${directory}${output_name}_reverse_paired.fq.gz ${directory}${output_name}_reverse_unpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:100
	join_paired_ends.py -f ${directory}${output_name}_forward_paired.fq.gz -r ${directory}${output_name}_reverse_paired.fq.gz -o ${directory}${output_name}_paired.fq -j 4 -p 1
	# #to check the number of surviving seqeunces use 
	wc -l ${directory}${output_name}_paired.fq/fastqjoin.join.fastq
	# # this will print out the number
	convert_fastaqual_fastq.py -f ${directory}${output_name}_paired.fq/fastqjoin.join.fastq -c fastq_to_fastaqual -o ${directory}


#variable_names
directory=P2_3-227388217/
fastq_file_1=P2-3_S41_L001_R1_001
fastq_file_2=P2-3_S41_L001_R2_001
output_name=P2-3
#commands
	java -jar /scratch/cod264/cod264/Trimmomatic-0.39/trimmomatic-0.39.jar PE -phred33 ${directory}${fastq_file_1}.fastq.gz  ${directory}${fastq_file_2}.fastq.gz ${directory}${output_name}_forward_paired.fq.gz ${directory}${output_name}_forward_unpaired.fq.gz ${directory}${output_name}_reverse_paired.fq.gz ${directory}${output_name}_reverse_unpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:100
	join_paired_ends.py -f ${directory}${output_name}_forward_paired.fq.gz -r ${directory}${output_name}_reverse_paired.fq.gz -o ${directory}${output_name}_paired.fq -j 4 -p 1
	# #to check the number of surviving seqeunces use 
	wc -l ${directory}${output_name}_paired.fq/fastqjoin.join.fastq
	# # this will print out the number
	convert_fastaqual_fastq.py -f ${directory}${output_name}_paired.fq/fastqjoin.join.fastq -c fastq_to_fastaqual -o ${directory}


#variable_names
directory=P3_1-227388218/
fastq_file_1=P3-1_S42_L001_R1_001
fastq_file_2=P3-1_S42_L001_R2_001
output_name=P3-1
#commands
	java -jar /scratch/cod264/cod264/Trimmomatic-0.39/trimmomatic-0.39.jar PE -phred33 ${directory}${fastq_file_1}.fastq.gz  ${directory}${fastq_file_2}.fastq.gz ${directory}${output_name}_forward_paired.fq.gz ${directory}${output_name}_forward_unpaired.fq.gz ${directory}${output_name}_reverse_paired.fq.gz ${directory}${output_name}_reverse_unpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:100
	join_paired_ends.py -f ${directory}${output_name}_forward_paired.fq.gz -r ${directory}${output_name}_reverse_paired.fq.gz -o ${directory}${output_name}_paired.fq -j 4 -p 1
	# #to check the number of surviving seqeunces use 
	wc -l ${directory}${output_name}_paired.fq/fastqjoin.join.fastq
	# # this will print out the number
	convert_fastaqual_fastq.py -f ${directory}${output_name}_paired.fq/fastqjoin.join.fastq -c fastq_to_fastaqual -o ${directory}

#variable_names
directory=P3_2-227388219/
fastq_file_1=P3-2_S43_L001_R1_001
fastq_file_2=P3-2_S43_L001_R2_001
output_name=P3-2
#commands
	java -jar /scratch/cod264/cod264/Trimmomatic-0.39/trimmomatic-0.39.jar PE -phred33 ${directory}${fastq_file_1}.fastq.gz  ${directory}${fastq_file_2}.fastq.gz ${directory}${output_name}_forward_paired.fq.gz ${directory}${output_name}_forward_unpaired.fq.gz ${directory}${output_name}_reverse_paired.fq.gz ${directory}${output_name}_reverse_unpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:100
	join_paired_ends.py -f ${directory}${output_name}_forward_paired.fq.gz -r ${directory}${output_name}_reverse_paired.fq.gz -o ${directory}${output_name}_paired.fq -j 4 -p 1
	#to check the number of surviving seqeunces use 
	wc -l ${directory}${output_name}_paired.fq/fastqjoin.join.fastq
	# this will print out the number
	convert_fastaqual_fastq.py -f ${directory}${output_name}_paired.fq/fastqjoin.join.fastq -c fastq_to_fastaqual -o ${directory}


#variable_names
directory=P3_3-227388215/
fastq_file_1=P3-3_S44_L001_R1_001
fastq_file_2=P3-3_S44_L001_R2_001
output_name=P3-3
#commands
	java -jar /scratch/cod264/cod264/Trimmomatic-0.39/trimmomatic-0.39.jar PE -phred33 ${directory}${fastq_file_1}.fastq.gz  ${directory}${fastq_file_2}.fastq.gz ${directory}${output_name}_forward_paired.fq.gz ${directory}${output_name}_forward_unpaired.fq.gz ${directory}${output_name}_reverse_paired.fq.gz ${directory}${output_name}_reverse_unpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:100
	join_paired_ends.py -f ${directory}${output_name}_forward_paired.fq.gz -r ${directory}${output_name}_reverse_paired.fq.gz -o ${directory}${output_name}_paired.fq -j 4 -p 1
	# #to check the number of surviving seqeunces use 
	wc -l ${directory}${output_name}_paired.fq/fastqjoin.join.fastq
	# # this will print out the number
	convert_fastaqual_fastq.py -f ${directory}${output_name}_paired.fq/fastqjoin.join.fastq -c fastq_to_fastaqual -o ${directory}
```

In this section we use Qiime2 to deblur the joined reads, perform clustering using VSEARCH, define phylogeny, and perform several different statistics and diversity measures. 

```{bash}
#Qiime2 Script
	# Version 2
	# Now uses vsearch for OTU picking, as per:
	# https://docs.qiime2.org/2019.4/tutorials/otu-clustering/
#
###
# Build qiime singularity 
###
		#First go to a directory with ~10GB of space
		#Download qiime container (Only once and it works for good)
		#singularity pull docker://qiime2/core:2019.4
		#To run qiime uncomment the next line:
		#singularity shell core_2019.4.sif
#
# Script Section
# Example script for running using all replicated associated with all sites.
	# CHANGE THESE
	sample_dir=Boris/
	fastq_dir = ${sample_dir}/fastq/
	
	#
	#Define directory
	base_dir=/scratch/ps163/qiime2/
	input_dir=${base_dir}/${sample_dir}/output
	mapping_file=${input_dir}/MappingFile_mangue.csv
	#
	qiime tools import \
	--type 'SampleData[SequencesWithQuality]' \
	--input-path ${fastq_dir} \
	--input-format CasavaOneEightSingleLanePerSampleDirFmt \
	--output-path ${input_dir}/demux-joined.qza
	  
	qiime dada2 denoise-single \
	 --i-demultiplexed-seqs ${input_dir}/demux-joined.qza \
	 --p-trim-left 3 \
	 --p-trunc-len 0 \
	 --o-representative-sequences ${input_dir}/pre-otu-rep-seqs-dada2.qza \
	 --o-table ${input_dir}/pre-otu-table-dada2.qza \
	 --o-denoising-stats ${input_dir}/stats-dada2.qza
	  
	qiime metadata tabulate \
	  --m-input-file ${input_dir}/stats-dada2.qza \
	  --o-visualization ${input_dir}/stats-dada2.qzv
	  
	#07.10.19: changed 'i-reference-sequences' to an unaligned format. vsearch does not support aligned reference sequences.
	qiime vsearch cluster-features-open-reference \
	  --i-table ${input_dir}/pre-otu-table-dada2.qza \
	  --i-sequences ${input_dir}/pre-otu-rep-seqs-dada2.qza \
	  --i-reference-sequences /scratch/ps163/qiime2/feature_classifier/silva_132_97_16S.qza \
	  --p-perc-identity 0.97 \
	  --o-clustered-table ${input_dir}table-dada2.qza \
	  --o-clustered-sequences ${input_dir}rep-seqs-dada2.qza \
	  --o-new-reference-sequences ${input_dir}new-ref-seqs-or-97.qza
	  
	qiime feature-table summarize \
	  --i-table ${input_dir}/table-dada2.qza \
	  --o-visualization ${input_dir}feature_table.qzv \
	  --m-sample-metadata-file ${mapping_file}
	  
	qiime feature-table tabulate-seqs \
	  --i-data ${input_dir}/rep-seqs-dada2.qza \
	  --o-visualization ${input_dir}dada2-rep-seqs.qzv
	  
	  #Phylogeny
	qiime phylogeny align-to-tree-mafft-fasttree \
	  --i-sequences ${input_dir}/rep-seqs-dada2.qza \
	  --o-alignment ${input_dir}/aligned-rep-seqs.qza \
	  --o-masked-alignment ${input_dir}/masked-aligned-rep-seqs.qza \
	  --o-tree ${input_dir}/unrooted-tree.qza \
	  --o-rooted-tree ${input_dir}/rooted-tree.qza
	  
	#to view trees 
	qiime tools export \
	  --input-path ${input_dir}/unrooted-tree.qza \
	  --output-path ${input_dir}/exported-unrooted-tree
	  
	#to view trees 
	qiime tools export \
	  --input-path ${input_dir}/rooted-tree.qza \
	  --output-path ${input_dir}/exported-rooted-tree
	  
	  #rarefac. 	11301
	 # #re  _x_ sampling_depth == 9340
	 # Core diversity analysis
	qiime diversity core-metrics-phylogenetic \
	  --i-phylogeny ${input_dir}/rooted-tree.qza \
	  --i-table ${input_dir}/table-dada2.qza \
	  --p-sampling-depth 9340 \
	  --m-metadata-file ${mapping_file} \
	  --output-dir ${input_dir}core-metrics-results
	  
	#Do not proceed group significance tests below. Go to Alpha raref.
	qiime diversity alpha-group-significance \
	  --i-alpha-diversity ${input_dir}/core-metrics-results/faith_pd_vector.qza \
	  --m-metadata-file ${mapping_file} \
	  --o-visualization ${input_dir}/core-metrics-results/faith-pd-group-significance.qzv

	qiime diversity alpha-group-significance \
	  --i-alpha-diversity ${input_dir}/core-metrics-results/evenness_vector.qza \
	  --m-metadata-file ${mapping_file} \
	  --o-visualization ${input_dir}/core-metrics-results/evenness-group-significance.qzv
	
	#07.11.19 - Changed metadata-column to "Site" instead of "InputFileName", the latter generated an error "All values in the grouping vector are unique". 
	qiime diversity beta-group-significance \
	  --i-distance-matrix  ${input_dir}/core-metrics-results/weighted_unifrac_distance_matrix.qza \
	  --m-metadata-file ${mapping_file} \
	  --m-metadata-column Site \
	  --o-visualization ${input_dir}/core-metrics-results/weighted-unifrac-site-significance.qzv \
	  --p-pairwise
	  
	#07.11.19 - Changed metadata-column to "Site" instead of "InputFileName", the latter generated an error "All values in the grouping vector are unique". 
	qiime diversity beta-group-significance \
	  --i-distance-matrix  ${input_dir}/core-metrics-results/unweighted_unifrac_distance_matrix.qza \
	  --m-metadata-file ${mapping_file} \
	  --m-metadata-column Site \
	  --o-visualization ${input_dir}/core-metrics-results/unweighted-unifrac-site-significance.qzv \
	  --p-pairwise
	  
	#Alpha raref.
	qiime diversity alpha-rarefaction \
	  --i-table ${input_dir}/table-dada2.qza \
	  --i-phylogeny ${input_dir}/rooted-tree.qza \
	  --p-max-depth 17000 \
	  --m-metadata-file ${mapping_file} \
	  --o-visualization ${input_dir}/core-metrics-results/alpha-rarefaction.qzv
	  
	  #taxonomy
	qiime feature-classifier classify-sklearn \
	  --i-classifier /scratch/ps163/qiime2/silva-132-99-515-806-nb-scikit0.20-classifier.qza \
	  --i-reads ${input_dir}/rep-seqs-dada2.qza \
	  --o-classification ${input_dir}/taxonomy.qza
	 
	qiime metadata tabulate \
	  --m-input-file ${input_dir}/taxonomy.qza \
	  --o-visualization ${input_dir}/taxonomy.qzv
	  
	qiime taxa barplot \
	  --i-table ${input_dir}/table-dada2.qza \
	  --i-taxonomy ${input_dir}/taxonomy.qza \
	  --m-metadata-file ${mapping_file} \
	  --o-visualization ${input_dir}/taxa-bar-plots.qzv
	  
# Example script for using all replicates of a single site, allowing for analysis of sites separately.
	# CHANGE THESE
	sample_dir=Boris_resubmit_seperate_sites/
	site=P1
	site_fastq = ${sample_dir}/fastq_${site}/
	
	#
	#Define directory
	base_dir=/scratch/ps163/qiime2/
	input_dir=${base_dir}/${sample_dir}/output_${site}
	mapping_file=${input_dir}/MappingFile_mangue.csv
	#
	qiime tools import \
	--type 'SampleData[SequencesWithQuality]' \
	--input-path ${site_fastq} \
	--input-format CasavaOneEightSingleLanePerSampleDirFmt \
	--output-path ${input_dir}/demux-joined.qza
	  
	qiime dada2 denoise-single \
	 --i-demultiplexed-seqs ${input_dir}/demux-joined.qza \
	 --p-trim-left 3 \
	 --p-trunc-len 0 \
	 --o-representative-sequences ${input_dir}/pre-otu-rep-seqs-dada2.qza \
	 --o-table ${input_dir}/pre-otu-table-dada2.qza \
	 --o-denoising-stats ${input_dir}/stats-dada2.qza
	  
	qiime metadata tabulate \
	  --m-input-file ${input_dir}/stats-dada2.qza \
	  --o-visualization ${input_dir}/stats-dada2.qzv
	  
	#07.10.19: changed 'i-reference-sequences' to an unaligned format. vsearch does not support aligned reference sequences.
	qiime vsearch cluster-features-open-reference \
	  --i-table ${input_dir}/pre-otu-table-dada2.qza \
	  --i-sequences ${input_dir}/pre-otu-rep-seqs-dada2.qza \
	  --i-reference-sequences /scratch/ps163/qiime2/feature_classifier/silva_132_97_16S.qza \
	  --p-perc-identity 0.97 \
	  --o-clustered-table ${input_dir}table-dada2.qza \
	  --o-clustered-sequences ${input_dir}rep-seqs-dada2.qza \
	  --o-new-reference-sequences ${input_dir}new-ref-seqs-or-97.qza
	  
	qiime feature-table summarize \
	  --i-table ${input_dir}/table-dada2.qza \
	  --o-visualization ${input_dir}feature_table.qzv \
	  --m-sample-metadata-file ${mapping_file}
	  
	qiime feature-table tabulate-seqs \
	  --i-data ${input_dir}/rep-seqs-dada2.qza \
	  --o-visualization ${input_dir}dada2-rep-seqs.qzv
	  
	  #Phylogeny
	qiime phylogeny align-to-tree-mafft-fasttree \
	  --i-sequences ${input_dir}/rep-seqs-dada2.qza \
	  --o-alignment ${input_dir}/aligned-rep-seqs.qza \
	  --o-masked-alignment ${input_dir}/masked-aligned-rep-seqs.qza \
	  --o-tree ${input_dir}/unrooted-tree.qza \
	  --o-rooted-tree ${input_dir}/rooted-tree.qza
	  
	#to view trees 
	qiime tools export \
	  --input-path ${input_dir}/unrooted-tree.qza \
	  --output-path ${input_dir}/exported-unrooted-tree
	  
	#to view trees 
	qiime tools export \
	  --input-path ${input_dir}/rooted-tree.qza \
	  --output-path ${input_dir}/exported-rooted-tree
	  
	  #rarefac. 	11301
	 # #re  _x_ sampling_depth == 9340
	 # Core diversity analysis
	qiime diversity core-metrics-phylogenetic \
	  --i-phylogeny ${input_dir}/rooted-tree.qza \
	  --i-table ${input_dir}/table-dada2.qza \
	  --p-sampling-depth 9340 \
	  --m-metadata-file ${mapping_file} \
	  --output-dir ${input_dir}core-metrics-results
	  
	#Do not proceed group significance tests below. Go to Alpha raref.
	qiime diversity alpha-group-significance \
	  --i-alpha-diversity ${input_dir}/core-metrics-results/faith_pd_vector.qza \
	  --m-metadata-file ${mapping_file} \
	  --o-visualization ${input_dir}/core-metrics-results/faith-pd-group-significance.qzv

	qiime diversity alpha-group-significance \
	  --i-alpha-diversity ${input_dir}/core-metrics-results/evenness_vector.qza \
	  --m-metadata-file ${mapping_file} \
	  --o-visualization ${input_dir}/core-metrics-results/evenness-group-significance.qzv
	
	#07.11.19 - Changed metadata-column to "Site" instead of "InputFileName", the latter generated an error "All values in the grouping vector are unique". 
	qiime diversity beta-group-significance \
	  --i-distance-matrix  ${input_dir}/core-metrics-results/weighted_unifrac_distance_matrix.qza \
	  --m-metadata-file ${mapping_file} \
	  --m-metadata-column Site \
	  --o-visualization ${input_dir}/core-metrics-results/weighted-unifrac-site-significance.qzv \
	  --p-pairwise
	  
	#07.11.19 - Changed metadata-column to "Site" instead of "InputFileName", the latter generated an error "All values in the grouping vector are unique". 
	qiime diversity beta-group-significance \
	  --i-distance-matrix  ${input_dir}/core-metrics-results/unweighted_unifrac_distance_matrix.qza \
	  --m-metadata-file ${mapping_file} \
	  --m-metadata-column Site \
	  --o-visualization ${input_dir}/core-metrics-results/unweighted-unifrac-site-significance.qzv \
	  --p-pairwise
	  
	#Alpha raref.
	qiime diversity alpha-rarefaction \
	  --i-table ${input_dir}/table-dada2.qza \
	  --i-phylogeny ${input_dir}/rooted-tree.qza \
	  --p-max-depth 17000 \
	  --m-metadata-file ${mapping_file} \
	  --o-visualization ${input_dir}/core-metrics-results/alpha-rarefaction.qzv
	  
	  #taxonomy
	qiime feature-classifier classify-sklearn \
	  --i-classifier /scratch/ps163/qiime2/silva-132-99-515-806-nb-scikit0.20-classifier.qza \
	  --i-reads ${input_dir}/rep-seqs-dada2.qza \
	  --o-classification ${input_dir}/taxonomy.qza
	 
	qiime metadata tabulate \
	  --m-input-file ${input_dir}/taxonomy.qza \
	  --o-visualization ${input_dir}/taxonomy.qzv
	  
	qiime taxa barplot \
	  --i-table ${input_dir}/table-dada2.qza \
	  --i-taxonomy ${input_dir}/taxonomy.qza \
	  --m-metadata-file ${mapping_file} \
	  --o-visualization ${input_dir}/taxa-bar-plots.qzv
	  
```

We are now moving to R to handle the files generated above to generate additional figures.

```{r library load}
library(tidyverse)
library(qiime2R)
library(phyloseq)
library(plyr)
library(ggplot2)
library(metacoder)
library(taxa)
library(dplyr)

#File location may need to be changed here

metadata<-read_tsv("MappingFile_mangue.csv")
feature_table<-read_qza("table-dada2.qza")

info_data <-feature_table$data
temptaxa <- read_qza('taxonomy.qza')
temptax<-temptaxa$data

rooted_tree<- read_qza("rooted_tree.qza")
root_tree <- rooted_tree$data

taxa_counts_transposed <- read.delim("taxa_counts_transposed.tab")
env_variables <- read.delim("env_variables.csv")
```

Code for Figure 2
Fig 2. Taxonomic abundances from all sample sites.

```{r figure 2}
#Fig 2. Taxonomic abundances from all sample sites.
#### Create phyloseq object
MG_data<-phyloseq(
  otu_table(info_data, taxa_are_rows = T),
  phy_tree(root_tree),
  tax_table(as.data.frame(taxtable_p1) %>% select(-Confidence) %>% column_to_rownames("Feature.ID") %>% as.matrix()), # transforming the taxonomy for compatibility with phyloseq
  sample_data(metadata %>% as.data.frame() %>% column_to_rownames("sample-id")))
### Subsample the most abundant phyla
phylum.sum = tapply(taxa_sums(MG_data), tax_table(MG_data)[, "Phylum"], sum, na.rm=TRUE) #objeto só com 6 filos mais abundantes
top6phyla = names(sort(phylum.sum, TRUE))[1:6]
MG_6p_new = prune_taxa((tax_table(MG_data)[, "Phylum"] %in% top6phyla), MG_data)
### Exclude OTUs that account for less than 1 percent of total (for more taxonomy levels)
Abund_otus1 <- filter_taxa(MG_data, function(x) sum(x > total*0.01) > 0, TRUE)
### Taxonomy barplots
plot_bar(Abund_otus1, "Phylum", fill="Class") + geom_bar(aes(color=Class, fill=Class), stat="identity", position="stack")
plot_bar(Abund_otus1, "Class", fill="Order") + geom_bar(aes(color=Order, fill=Order), stat="identity", position="stack")
plot_bar(Abund_otus1, "Order", fill="Family") + geom_bar(aes(color=Family, fill=Family), stat="identity", position="stack")+ theme(legend.position="bottom")

```

Fig. 5. Significant correlation of salinity and organic matter with prokaryotic communities.

```{r figure 5}
#Fig. 5. Significant correlation of salinity and organic matter with prokaryotic communities.
library(vegan)

my_varechem = env_variables
my_varespec = taxa_counts_transposed
rownames(my_varespec) <- my_varespec$OTU_ID
my_varespec <- my_varespec[-c(1)]

#Using Mantel

Salinity_DM <- vegdist(env_variables[,3])
Temperature_DM <- vegdist(env_variables[,4])
OrganicMatter_DM <- vegdist(env_variables[,5])
taxa_dist <- vegdist(my_varespec) # Creates distance matrix of the OTUs

taxa_salinity_Mantel <- mantel(taxa_dist, Salinity_DM, permutations = 999)
taxa_salinity_Mantel
taxa_temp_Mantel <- mantel(taxa_dist, Temperature_DM, permutations = 999)
taxa_temp_Mantel
taxa_OM_Mantel <- mantel(taxa_dist, OrganicMatter_DM, permutations = 999)
taxa_OM_Mantel

#Using NMDS, envfit

pdf('NMDS_taxa.pdf')
ord <- metaMDS((my_varespec), try=1000, k = 3)
(fit <- envfit(ord, my_varechem, perm = 999))

priSite <- diversity(my_varespec, index = "invsimpson", MARGIN = 1)

plot(ord)
orditorp(ord, display = "sites", priority = priSite, scaling = 3,
         col = "blue", cex = 1, pch = 19)

scores(fit, "vectors")

plot(fit)
plot(fit, p.max = 0.9, col = "blue")
plot(fit, p.max = 0.05, col = "red")
dev.off()

print(fit)

```

PICRUSt2 is used to generate KO functional abundances which are used in metabolic tagging of 
site-specific taxa enrichment (Figure 6, 8) and site-specific KO and pathway enrichment (Figure 7).

```{bash}
# feature-table.biom, dna-sequences.fasta is QIIME2 output
# 
picrust2_pipeline.py \
	--stratified \
	--per_sequence_contrib \
	-p 4 \
	-s dna-sequences.fasta \
	-i feature-table.biom \
	-o picrust2_out_pipeline
```

```{r glm for Picrust2}
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")

BiocManager::install("ALDEx2")

library(ALDEx2)

#Carbon_Nitrogen_Phosphorus_Sulfur metabolism pathways from KEGG
CNPS_metabolism <- read.table("CNPS_metabolism.txt")
#Predicted KO functional abundances from PICRUSt2
pred_metagenome_unstrat <- read.delim("pred_metagenome_unstrat.tsv")
#Predicted MetaCyc Pathway functional abundances from PICRUSt2
path_abun_unstrat <- read.delim("path_abun_unstrat.tsv")

### KOs 
metagenome <- pred_metagenome_unstrat
rownames(metagenome) <- metagenome$X.function
metagenome <- metagenome[-c(1)]

conds <- c(rep("Sub", 3), rep('Int', 3), rep("Sec", 3))
ko <- aldex.clr(round(metagenome), conds, mc.samples=333, denom="all", verbose=F)
ko.kw <- aldex.kw(ko)

sig_kos <- subset(ko.kw, (ko.kw$glm.ep <= 0.05))
write.csv(sig_kos, "aldex_significant_all_KO.csv")

### Metabolism associated KOs 
metagenome <- pred_metagenome_unstrat
#note we are subsetting the set of all KOs to only be those associated with Carbon_Nitrogen_Phosphorus_Sulfur metabolism
metagenome <-merge(metagenome, CNPS_metabolism, by.x='X.function', by.y='V1')
rownames(metagenome) <- metagenome$X.function
metagenome <- metagenome[-c(1)]

conds <- c(rep("Sub", 3), rep('Int', 3), rep("Sec", 3))
ko <- aldex.clr(round(metagenome), conds, mc.samples=333, denom="all", verbose=F)
ko.kw <- aldex.kw(ko)

sig_cnps <- subset(ko.kw, (ko.kw$glm.ep <= 0.05))
write.csv(sig_cnps, "aldex_significant_CNPS_KO.csv")

### MetaCyc pathways
pathway <- path_abun_unstrat
rownames(pathway) <- pathway$X.pathway
pathway <- pathway[-c(1)]

conds <- c(rep("Sub", 3), rep('Int', 3), rep("Sec", 3))
x <- aldex.clr(round(pathway), conds, mc.samples=333, denom="all", verbose=F)
x.kw <- aldex.kw(x)

sig_pathway <- subset(x.kw, x.kw$glm.ep <= 0.05)
write.csv(sig_pathway, "aldex_significant_pathway.csv")


```

```{bash}
#biom is used to convert the QIIME2 generated file into a tab-separated file
biom convert -i feature-table.biom -o feature-table.biom.txt --to-tsv

# novembro identifies site specific enrichment of taxonomic populations 
python novembro.py -f feature-table.biom.txt -t taxonomy.tsv -s silva -o taxa_counts.tab

# sigilo generates heatmaps using the aldex identified significant KOs or pathways 
python sigilo --generate_heatmap -i pred_metagenome_unstrat.tsv -sig aldex_significant_CNPS_KO.csv -o significant_CNPS_KO
python sigilo --generate_heatmap -i pred_metagenome_unstrat.tsv -sig aldex_significant_pathway.csv -o significant_pathway

# sigilo can also find taxa specific enrichment
python sigilo --find_enrichment -c pred_metagenome_contrib.tsv -t taxonomy.tsv -p metabolism_KOs/ -select select_taxa.tsv -pct 0.1 -pval 0.05 -o metagenome_contrib


```

Code for Figure 8
Fig 8. Phylogenetic tree 

```{r figure 8}
#Fig 8. Phylogenetic tree of life at the family level.

feature_taxonomy <- read.delim("feature_taxonomy.tab")

obj <- parse_tax_data(feature_taxonomy,
                      class_cols = "taxa", # the column that contains taxonomic information
                      class_sep = ";", # The character used to separate taxa in the classification
                      class_regex = "^(.+)__(.+)$", # Regex identifying where the data for each taxon is
                      class_key = c(tax_rank = "info", # A key describing each regex capture group
                                    tax_name = "taxon_name"))

obj$data$tax_data <- zero_low_counts(obj, data = "tax_data", min_count = 100)
obj <- filter_obs(obj, target = "tax_data", ! no_reads, drop_taxa = TRUE)

set.seed(1) # This makes the plot appear the same each time it is run 
heat_tree(obj, 
          node_label = taxon_names,
          node_size = n_obs,
          node_color = n_obs, 
          node_size_axis_label = "OTU count",
          node_color_axis_label = "Samples with reads",
          output_file = "heat_tree.pdf") # Saves the plot as a pdf file)

```


Figures are further altered in post using Adobe Illustrator to improve legibility. 
